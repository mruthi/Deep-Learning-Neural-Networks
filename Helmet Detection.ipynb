{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9884f318-8922-4493-ad43-ead678fafc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7f3136-50ee-4341-a5f6-45e0017da0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x512 (no detections), 2789.6ms\n",
      "Speed: 7.1ms preprocess, 2789.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 2839.8ms\n",
      "Speed: 11.5ms preprocess, 2839.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 Helmet, 2784.4ms\n",
      "Speed: 24.8ms preprocess, 2784.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 Helmet, 3350.6ms\n",
      "Speed: 36.6ms preprocess, 3350.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 2 Helmets, 2940.6ms\n",
      "Speed: 20.4ms preprocess, 2940.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 Helmet, 2862.6ms\n",
      "Speed: 45.8ms preprocess, 2862.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 Helmet, 2793.5ms\n",
      "Speed: 12.7ms preprocess, 2793.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 Helmet, 2820.0ms\n",
      "Speed: 19.9ms preprocess, 2820.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 Helmet, 2827.0ms\n",
      "Speed: 18.5ms preprocess, 2827.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 Helmet, 2864.7ms\n",
      "Speed: 31.0ms preprocess, 2864.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 2800.6ms\n",
      "Speed: 37.9ms preprocess, 2800.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 2819.4ms\n",
      "Speed: 13.4ms preprocess, 2819.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 2808.9ms\n",
      "Speed: 30.1ms preprocess, 2808.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 2831.6ms\n",
      "Speed: 9.1ms preprocess, 2831.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 2830.5ms\n",
      "Speed: 19.7ms preprocess, 2830.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 2834.4ms\n",
      "Speed: 24.7ms preprocess, 2834.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 512)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained YOLO model (Change \"best.pt\" if you trained a custom model)\n",
    "model = YOLO(\"best.pt\")  \n",
    "\n",
    "# Class Labels (Modify based on training)\n",
    "HELMET_CLASS = \"Helmet\"\n",
    "NO_HELMET_CLASS = \"No Helmet\"\n",
    "\n",
    "# Choose input type: \"image\", \"video\", or \"webcam\"\n",
    "input_type = \"webcam\"  \n",
    "\n",
    "if input_type == \"image\":\n",
    "    image_path = \"test_helmet.jpg\"\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    results = model(image)\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes.xyxy.cpu().numpy()\n",
    "        classes = result.boxes.cls.cpu().numpy()\n",
    "        confidences = result.boxes.conf.cpu().numpy()\n",
    "\n",
    "        for box, cls, conf in zip(boxes, classes, confidences):\n",
    "            x1, y1, x2, y2 = map(int, box[:4])\n",
    "            confidence = conf * 100  # Convert to percentage\n",
    "            label = HELMET_CLASS if int(cls) == 0 else NO_HELMET_CLASS\n",
    "            color = (0, 255, 0) if int(cls) == 0 else (0, 0, 255)\n",
    "\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(\n",
    "                image, \n",
    "                f\"{label} {confidence:.1f}%\", \n",
    "                (x1, y1 - 10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.5, \n",
    "                color, \n",
    "                2\n",
    "            )\n",
    "\n",
    "    cv2.imshow(\"Helmet Detection\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "elif input_type in [\"video\", \"webcam\"]:\n",
    "    cap = cv2.VideoCapture(0 if input_type == \"webcam\" else \"test_video.mp4\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame)\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes.xyxy.cpu().numpy()\n",
    "            classes = result.boxes.cls.cpu().numpy()\n",
    "            confidences = result.boxes.conf.cpu().numpy()\n",
    "\n",
    "            for box, cls, conf in zip(boxes, classes, confidences):\n",
    "                x1, y1, x2, y2 = map(int, box[:4])\n",
    "                confidence = conf * 100  # Convert to percentage\n",
    "                label = HELMET_CLASS if int(cls) == 0 else NO_HELMET_CLASS\n",
    "                color = (0, 255, 0) if int(cls) == 0 else (0, 0, 255)\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(\n",
    "                    frame, \n",
    "                    f\"{label} {confidence:.1f}%\", \n",
    "                    (x1, y1 - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.5, \n",
    "                    color, \n",
    "                    2\n",
    "                )\n",
    "\n",
    "        cv2.imshow(\"Helmet Detection\", frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a636f1f-b6e5-4962-ad2b-0ecce8c71b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
